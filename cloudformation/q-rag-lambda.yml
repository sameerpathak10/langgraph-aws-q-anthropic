AWSTemplateFormatVersion: "2010-09-09"
Description: >
  Creates a Lambda for RAG/LLM routing, and provisions an Amazon Q Business
  Application, Index, and S3-backed Data Source. Grants the Lambda permissions
  to call Amazon Q Business and Amazon Bedrock runtime.

Parameters:
  LambdaS3Bucket:
    Type: String
    Default: langgraph-poc-bucket
    Description: S3 bucket containing the ZIP package for the main Lambda.
  LambdaS3Key:
    Type: String
    Default: langgraph_lambda.zip
    Description: S3 key for the ZIP package.
  LambdaFunctionName:
    Type: String
    Default: langgraph-rag-lambda
    Description: Lambda function name.
  ApplicationName:
    Type: String
    Default: LangGraphQApp
    Description: Display name of the Amazon Q Business application.
  IndexDisplayName:
    Type: String
    Default: LangGraphQIndex
    Description: Display name of the Amazon Q Business index.
  DataSourceName:
    Type: String
    Default: LangGraphS3DataSource
    Description: Display name of the S3-backed data source.
  DataSourceBucketName:
    Type: String
    Default: "langgraph-aws-q-poc-data-source-bucket"
    Description: >
      (Optional) Name of the S3 bucket for the data source. If left empty,
      a unique bucket name will be generated.
  ApplicationIdentityType:
    Type: String
    Default: ANONYMOUS
    Description: Identity type for the Q application. Allowed ANONYMOUS, etc.
  Runtime:
    Type: String
    Default: python3.11

Resources:
  LambdaExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Sub "${LambdaFunctionName}-exec-role"
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      Path: /
      Policies:
        - PolicyName: LambdaBasic
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: Allow
                Action:
                  - logs:CreateLogGroup
                  - logs:CreateLogStream
                  - logs:PutLogEvents
                Resource: "arn:aws:logs:*:*:*"
        - PolicyName: BedrockAndQPolicy
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: Allow
                Action:
                  - bedrock:InvokeModel
                  - bedrock-runtime:*
                Resource: "*"
              - Effect: Allow
                Action: "qbusiness:*"
                Resource: "*"
              - Effect: Allow
                Action:
                  - aws-marketplace:ViewSubscriptions
                  - aws-marketplace:Subscribe
                Resource: "*"

  AppFunction:
    Type: AWS::Lambda::Function
    DependsOn: QProvisionerCustomResource
    Properties:
      FunctionName: !Ref LambdaFunctionName
      Handler: main.lambda_handler
      Role: !GetAtt LambdaExecutionRole.Arn
      Runtime: !Ref Runtime
      Timeout: 20
      MemorySize: 512
      Code:
        S3Bucket: !Ref LambdaS3Bucket
        S3Key: !Ref LambdaS3Key
      Environment:
        Variables:
          Q_APP_ID: !GetAtt QProvisionerCustomResource.ApplicationId
          Q_INDEX_ID: !GetAtt QProvisionerCustomResource.IndexId
      Tags:
        - Key: project
          Value: langgraph

  QProvisionerRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      Path: /
      Policies:
        - PolicyName: QProvisionerPolicy
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: Allow
                Action:
                  - logs:CreateLogGroup
                  - logs:CreateLogStream
                  - logs:PutLogEvents
                Resource: "arn:aws:logs:*:*:*"
              - Effect: Allow
                Action:
                  - qbusiness:CreateApplication
                  - qbusiness:ListApplications
                  - qbusiness:GetApplication
                  - qbusiness:CreateIndex
                  - qbusiness:ListIndices
                  - qbusiness:GetIndex
                  - qbusiness:CreateDataSource
                  - qbusiness:ListDataSources
                  - qbusiness:ListDataSourceSyncJobs
                  - qbusiness:StartDataSourceSync
                  - qbusiness:GetDataSource
                  - qbusiness:ListWebExperiences
                Resource: "*"
              - Effect: Allow
                Action:
                  - iam:CreateServiceLinkedRole
                Resource: "*"
                Condition:
                  StringEquals:
                    iam:AWSServiceName: "qbusiness.amazonaws.com"
              - Effect: Allow
                Action:
                  - s3:CreateBucket
                  - s3:GetBucketLocation
                Resource: "*"
              - Effect: Allow
                Action:
                  - iam:CreateRole
                  - iam:GetRole
                  - iam:PutRolePolicy
                  - iam:PassRole
                Resource: "arn:aws:iam::*:role/QDataSource*"

  QProvisionerFunction:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: !Sub "${LambdaFunctionName}-q-provisioner"
      Handler: index.handler
      Role: !GetAtt QProvisionerRole.Arn
      Runtime: !Ref Runtime
      Timeout: 600
      MemorySize: 256
      Code:
        ZipFile: |
          import json
          import boto3
          import urllib.request
          import urllib.error
          import logging
          import traceback
          import time
          from botocore.exceptions import ClientError

          logger = logging.getLogger()
          logger.setLevel(logging.INFO)

          q = boto3.client('qbusiness')
          iam = boto3.client('iam')
          s3 = boto3.client('s3')

          def send_response(event, context, status, data=None, reason=None):
              physical_id = (data or {}).get('ApplicationId', context.log_stream_name if context else 'q-provisioner')
              resp = {
                  'Status': status,
                  'Reason': reason or '',
                  'PhysicalResourceId': physical_id,
                  'StackId': event.get('StackId'),
                  'RequestId': event.get('RequestId'),
                  'LogicalResourceId': event.get('LogicalResourceId'),
                  'Data': data or {}
              }
              body = json.dumps(resp).encode('utf-8')
              req = urllib.request.Request(event['ResponseURL'], data=body, method='PUT')
              req.add_header('Content-Type', '')
              req.add_header('Content-Length', str(len(body)))
              try:
                  urllib.request.urlopen(req)
              except Exception as e:
                  logger.exception('Failed to send CFN response')

          def wait_for_status(callback, wait_secs=15, max_attempts=40):
              for i in range(max_attempts):
                  status, resource_id = callback()
                  if status == 'ACTIVE':
                      return resource_id
                  logger.info(f"Resource not ready, waiting... (Attempt {i+1}/{max_attempts})")
                  time.sleep(wait_secs)
              raise RuntimeError("Resource did not become active in time.")

          def ensure_application(display_name, identity_type='ANONYMOUS'):
              resp = q.list_applications()
              for app in resp.get('applications', []):
                  if app.get('displayName') == display_name:
                      logger.info(f"Found existing application: {app['applicationId']}")
                      return app['applicationId']

              logger.info(f"Creating application '{display_name}'...")
              resp = q.create_application(displayName=display_name, identityType=identity_type)
              app_id = resp['applicationId']

              def check_app_status():
                  app_details = q.get_application(applicationId=app_id)
                  return app_details.get('status', 'CREATING'), app_id
              
              return wait_for_status(check_app_status)

          def ensure_index(app_id, display_name):
              resp = q.list_indices(applicationId=app_id)
              for index in resp.get('indices', []):
                  if index.get('displayName') == display_name:
                      logger.info(f"Found existing index: {index['indexId']}")
                      return index['indexId']
              
              logger.info(f"Creating index '{display_name}'...")
              resp = q.create_index(applicationId=app_id, displayName=display_name)
              index_id = resp['indexId']

              def check_index_status():
                  index_details = q.get_index(applicationId=app_id, indexId=index_id)
                  return index_details.get('status', 'CREATING'), index_id
              
              return wait_for_status(check_index_status)

          def ensure_data_source_role(role_name, bucket_name):
              try:
                  role_resp = iam.get_role(RoleName=role_name)
                  role_arn = role_resp['Role']['Arn']
                  logger.info(f"Found existing role {role_name}")
              except ClientError as e:
                  if e.response['Error']['Code'] == 'NoSuchEntity':
                      logger.info(f"Creating role {role_name}...")
                      assume_role_policy = {
                          "Version": "2012-10-17",
                          "Statement": [{
                              "Effect": "Allow",
                              "Principal": {"Service": "qbusiness.amazonaws.com"},
                              "Action": "sts:AssumeRole"
                          }]
                      }
                      create_resp = iam.create_role(
                          RoleName=role_name,
                          AssumeRolePolicyDocument=json.dumps(assume_role_policy)
                      )
                      role_arn = create_resp['Role']['Arn']
                      time.sleep(10) # Give role time to propagate
                  else:
                      raise

              logger.info(f"Attaching policy to role {role_name}")
              policy_doc = {
                  "Version": "2012-10-17",
                  "Statement": [{
                      "Effect": "Allow",
                      "Action": ["s3:GetObject"],
                      "Resource": [f"arn:aws:s3:::{bucket_name}/*"]
                  }, {
                      "Effect": "Allow",
                      "Action": ["s3:ListBucket"],
                      "Resource": [f"arn:aws:s3:::{bucket_name}"]
                  }]
              }
              iam.put_role_policy(
                  RoleName=role_name,
                  PolicyName='QDataSourceS3Policy',
                  PolicyDocument=json.dumps(policy_doc)
              )
              return role_arn

          def ensure_data_source(app_id, index_id, role_arn, bucket_name, ds_name):
              resp = q.list_data_sources(applicationId=app_id, indexId=index_id)
              for ds in resp.get('dataSources', []):
                  if ds.get('displayName') == ds_name:
                      logger.info(f"Found existing data source: {ds['dataSourceId']}")
                      return ds['dataSourceId']

              logger.info(f"Creating data source '{ds_name}'...")
              config = {"bucketName": bucket_name}
              resp = q.create_data_source(
                  applicationId=app_id,
                  indexId=index_id,
                  displayName=ds_name,                                    
                  roleArn=role_arn,
                  configuration={ 
                    "type": "S3",
                    "syncMode": "FULL_CRAWL",
                    "connectionConfiguration": {
                      "repositoryEndpointMetadata": {
                        "BucketName": bucket_name
                      }
                    },
                  }
              )
              ds_id = resp['dataSourceId']
              
              def check_ds_status():
                  ds_details = q.get_data_source(applicationId=app_id, indexId=index_id, dataSourceId=ds_id)
                  return ds_details.get('status', 'CREATING'), ds_id

              return wait_for_status(check_ds_status)

          def start_sync(app_id, index_id, ds_id):
              syncs = q.list_data_source_sync_jobs(applicationId=app_id, indexId=index_id, dataSourceId=ds_id)
              if not syncs.get('history'):
                  logger.info(f"Starting initial sync for data source {ds_id}")
                  q.start_data_source_sync_job(applicationId=app_id, indexId=index_id, dataSourceId=ds_id)

          def handler(event, context):
              logger.info('Event: %s', json.dumps(event))
              try:
                  if event['RequestType'] == 'Delete':
                      send_response(event, context, 'SUCCESS', {})
                      return

                  props = event.get('ResourceProperties', {})
                  account_id = context.invoked_function_arn.split(":")[4]
                  region = context.invoked_function_arn.split(":")[3]
                  
                  # 1. Application
                  app_id = ensure_application(props['ApplicationName'], props['ApplicationIdentityType'])
                  
                  # 2. Index
                  index_id = ensure_index(app_id, props['IndexDisplayName'])

                  # 3. S3 Bucket and Role for Data Source
                  bucket_name = props.get('DataSourceBucketName') or f"q-ds-bucket-{account_id}-{region}-{app_id[:8]}"
                  try:
                      s3.head_bucket(Bucket=bucket_name)
                      logger.info(f"Bucket {bucket_name} already exists.")
                  except ClientError:
                      logger.info(f"Creating bucket {bucket_name}")
                      if region != 'us-east-1':
                        s3.create_bucket(Bucket=bucket_name, CreateBucketConfiguration={'LocationConstraint': region})
                      else:
                        s3.create_bucket(Bucket=bucket_name)

                  role_name = f"QDataSourceRole-{app_id[:12]}"
                  role_arn = ensure_data_source_role(role_name, bucket_name)
                  
                  # 4. Data Source and Sync
                  ds_id = ensure_data_source(app_id, index_id, role_arn, bucket_name, props['DataSourceName'])
                  start_sync(app_id, index_id, ds_id)
                  
                  data = {
                      'ApplicationId': app_id,
                      'IndexId': index_id,
                      'DataSourceId': ds_id,
                      'DataSourceBucketName': bucket_name,
                  }
                  send_response(event, context, 'SUCCESS', data)

              except Exception as e:
                  logger.error('Provisioner failed: %s', traceback.format_exc())
                  send_response(event, context, 'FAILED', reason=str(e))

  QProvisionerCustomResource:
    Type: Custom::QProvisioner
    Properties:
      ServiceToken: !GetAtt QProvisionerFunction.Arn
      ApplicationName: !Ref ApplicationName
      IndexDisplayName: !Ref IndexDisplayName
      DataSourceName: !Ref DataSourceName
      DataSourceBucketName: !Ref DataSourceBucketName
      ApplicationIdentityType: !Ref ApplicationIdentityType

Outputs:
  LambdaFunctionArn:
    Description: ARN of the runtime Lambda function
    Value: !GetAtt AppFunction.Arn
  QApplicationId:
    Description: ApplicationId created for Q Business
    Value: !GetAtt QProvisionerCustomResource.ApplicationId
  QIndexId:
    Description: The ID of the created index.
    Value: !GetAtt QProvisionerCustomResource.IndexId
  QDataSourceId:
    Description: The ID of the created data source.
    Value: !GetAtt QProvisionerCustomResource.DataSourceId
  DataSourceBucketName:
    Description: Name of the S3 bucket created for the data source.
    Value: !GetAtt QProvisionerCustomResource.DataSourceBucketName

Metadata:
  Notes: |
    This stack provisions a full Amazon Q Business application, including an
    index and an S3 data source. Upload documents to the S3 bucket specified
    in the Outputs to have them indexed by Q.