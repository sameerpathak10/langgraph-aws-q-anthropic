AWSTemplateFormatVersion: "2010-09-09"
Description: >
  Creates a Lambda for RAG/LLM routing using the provided `main.py` handler,
  and provisions a complete Amazon Q Business Application, Index, Retriever,
  and S3 Data Source via a Lambda-backed custom resource.

Parameters:
  LambdaS3Bucket:
    Type: String
    Default: langgraph-poc-bucket
    Description: S3 bucket containing the ZIP package for the main application Lambda.
  LambdaS3Key:
    Type: String
    Description: S3 key for the ZIP package (e.g., langgraph_lambda.zip).
    Default: langgraph_lambda.zip
  LambdaFunctionName:
    Type: String
    Default: langgraph-rag-lambda
    Description: Lambda function name for the main application.
  ApplicationName:
    Type: String
    Default: LangGraphQApp
    Description: Display name of the Amazon Q Business application to create.
  IndexDisplayName:
    Type: String
    Default: LangGraphQIndex
    Description: Display name for the Amazon Q Business index.
  DataSourceName:
    Type: String
    Default: LangGraphS3DataSource
    Description: Display name for the Amazon Q S3 data source.
  DataSourceBucketName:
    Type: String
    Default: ""
    Description: (Optional) Name of an existing S3 bucket to use as the data source. If empty, a new bucket will be created.
  ApplicationIdentityType:
    Type: String
    Default: ANONYMOUS
    Description: Identity type for the Q application. ANONYMOUS is required for this sample.
  Runtime:
    Type: String
    Default: python3.11

Resources:
  LambdaExecutionRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Sub "${LambdaFunctionName}-exec-role"
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Principal:
              Service: [lambda.amazonaws.com]
            Action: [sts:AssumeRole]
      Path: /
      Policies:
        - PolicyName: LambdaBasic
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: Allow
                Action:
                  - logs:CreateLogGroup
                  - logs:CreateLogStream
                  - logs:PutLogEvents
                Resource: "arn:aws:logs:*:*:*"
        - PolicyName: BedrockAndQPolicy
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: Allow
                Action:
                  - bedrock:InvokeModel
                Resource: "arn:aws:bedrock:*::foundation-model/*"
              - Effect: Allow
                Action:
                  - qbusiness:ChatSync
                Resource: !GetAtt QProvisionerCustomResource.ApplicationArn
              - Effect: Allow
                Action:
                  - aws-marketplace:ViewSubscriptions
                  - aws-marketplace:Subscribe
                Resource: "*"

  AppFunction:
    Type: AWS::Lambda::Function
    DependsOn: QProvisionerCustomResource
    Properties:
      FunctionName: !Ref LambdaFunctionName
      Handler: main.lambda_handler
      Role: !GetAtt LambdaExecutionRole.Arn
      Runtime: !Ref Runtime
      Timeout: 20
      MemorySize: 512
      Code:
        S3Bucket: !Ref LambdaS3Bucket
        S3Key: !Ref LambdaS3Key
      Environment:
        Variables:
          Q_APP_ID: !GetAtt QProvisionerCustomResource.ApplicationId
          Q_RETRIEVER_ID: !GetAtt QProvisionerCustomResource.RetrieverId
      Tags:
        - Key: project
          Value: langgraph

  QProvisionerRole:
    Type: AWS::IAM::Role
    Properties:
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Principal:
              Service: [lambda.amazonaws.com]
            Action: [sts:AssumeRole]
      Path: /
      Policies:
        - PolicyName: QProvisionerPolicy
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: Allow
                Action:
                  - logs:CreateLogGroup
                  - logs:CreateLogStream
                  - logs:PutLogEvents
                Resource: "arn:aws:logs:*:*:*"
              - Effect: Allow
                Action:
                  - qbusiness:CreateApplication
                  - qbusiness:ListApplications
                  - qbusiness:GetApplication
                  - qbusiness:CreateIndex
                  - qbusiness:ListIndices
                  - qbusiness:GetIndex
                  - qbusiness:CreateDataSource
                  - qbusiness:ListDataSources
                  - qbusiness:GetDataSource
                  - qbusiness:StartDataSourceSyncJob
                  - qbusiness:ListDataSourcesSyncJobs
                  - qbusiness:CreateRetriever
                  - qbusiness:ListRetrievers
                  - qbusiness:GetRetriever
                  - s3:CreateBucket
                  - s3:HeadBucket
                  - s3:PutBucketPolicy
                  - iam:CreateRole
                  - iam:GetRole
                  - iam:PutRolePolicy
                  - iam:PassRole
                Resource: "*"
              - Effect: Allow
                Action: iam:CreateServiceLinkedRole
                Resource: "*"
                Condition:
                  StringEquals:
                    iam:AWSServiceName: "qbusiness.amazonaws.com"

  QProvisionerFunction:
    Type: AWS::Lambda::Function
    Properties:
      FunctionName: !Sub "${LambdaFunctionName}-q-provisioner"
      Handler: index.handler
      Role: !GetAtt QProvisionerRole.Arn
      Runtime: python3.11
      Timeout: 900
      MemorySize: 256
      Code:
        ZipFile: |
          import json
          import boto3
          import urllib.request
          import time
          import logging
          import traceback
          from botocore.exceptions import ClientError

          logger = logging.getLogger()
          logger.setLevel(logging.INFO)

          q = boto3.client('qbusiness')
          iam = boto3.client('iam')
          s3 = boto3.client('s3')

          def send_response(event, context, status, data=None, reason=None):
              payload = {
                  'Status': status,
                  'Reason': reason or f"See CloudWatch Log Stream: {context.log_stream_name}",
                  'PhysicalResourceId': data.get('ApplicationId', context.log_stream_name),
                  'StackId': event['StackId'],
                  'RequestId': event['RequestId'],
                  'LogicalResourceId': event['LogicalResourceId'],
                  'Data': data,
              }
              logger.info(f"Sending response: {json.dumps(payload)}")
              try:
                  body = json.dumps(payload).encode('utf-8')
                  req = urllib.request.Request(event['ResponseURL'], data=body, headers={'Content-Type': '', 'Content-Length': len(body)}, method='PUT')
                  with urllib.request.urlopen(req) as resp:
                      logger.info(f"Response status: {resp.status}")
              except Exception:
                  logger.exception("Failed to send CFN response")

          def wait_for_status(check_function, expected_status='ACTIVE', max_attempts=40, delay=15):
              for i in range(max_attempts):
                  status, resource_id = check_function()
                  logger.info(f"Checking status for {resource_id}: current status is {status} (Attempt {i+1}/{max_attempts})")
                  if status == expected_status:
                      return resource_id
                  if status in ['FAILED', 'ERROR']:
                      raise Exception(f"Resource {resource_id} entered FAILED state.")
                  time.sleep(delay)
              raise Exception(f"Resource did not reach {expected_status} state after {max_attempts * delay} seconds.")

          def ensure_application(display_name, identity_type):
              resp = q.list_applications()
              for app in resp.get('applications', []):
                  if app.get('displayName') == display_name:
                      logger.info(f"Found existing application: {app['applicationId']}")
                      return app['applicationId']
              
              logger.info(f"Creating application '{display_name}'...")
              resp = q.create_application(displayName=display_name, identityType=identity_type)
              app_id = resp['applicationId']

              def check_app_status():
                  app_details = q.get_application(applicationId=app_id)
                  return app_details.get('status', 'CREATING'), app_id
              
              return wait_for_status(check_app_status)

          def ensure_index(app_id, display_name):
              resp = q.list_indices(applicationId=app_id)
              for index in resp.get('indices', []):
                  if index.get('displayName') == display_name:
                      logger.info(f"Found existing index: {index['indexId']}")
                      return index['indexId']

              logger.info(f"Creating index '{display_name}'...")
              resp = q.create_index(applicationId=app_id, displayName=display_name)
              index_id = resp['indexId']
              
              def check_index_status():
                  index_details = q.get_index(applicationId=app_id, indexId=index_id)
                  return index_details.get('status', 'CREATING'), index_id
              
              return wait_for_status(check_index_status)

          def ensure_data_source_role(role_name, bucket_name):
              try:
                  role_resp = iam.get_role(RoleName=role_name)
                  role_arn = role_resp['Role']['Arn']
                  logger.info(f"Found existing role {role_name}")
              except ClientError as e:
                  if e.response['Error']['Code'] == 'NoSuchEntityException':
                      logger.info(f"Creating role {role_name}...")
                      assume_role_policy = {
                          "Version": "2012-10-17",
                          "Statement": [{"Effect": "Allow", "Principal": {"Service": "qbusiness.amazonaws.com"}, "Action": "sts:AssumeRole"}]
                      }
                      create_resp = iam.create_role(RoleName=role_name, AssumeRolePolicyDocument=json.dumps(assume_role_policy))
                      role_arn = create_resp['Role']['Arn']
                      time.sleep(10) # Give role time to propagate
                  else:
                      raise

              logger.info(f"Attaching policy to role {role_name}")
              policy_doc = {
                  "Version": "2012-10-17",
                  "Statement": [
                      {"Effect": "Allow", "Action": "s3:GetObject", "Resource": f"arn:aws:s3:::{bucket_name}/*"},
                      {"Effect": "Allow", "Action": "s3:ListBucket", "Resource": f"arn:aws:s3:::{bucket_name}"}
                  ]
              }
              iam.put_role_policy(RoleName=role_name, PolicyName='QDataSourceS3Policy', PolicyDocument=json.dumps(policy_doc))
              return role_arn

          def ensure_data_source(app_id, index_id, role_arn, bucket_name, ds_name):
              resp = q.list_data_sources(applicationId=app_id, indexId=index_id)
              for ds in resp.get('dataSources', []):
                  if ds.get('displayName') == ds_name:
                      logger.info(f"Found existing data source: {ds['dataSourceId']}")
                      return ds['dataSourceId']

              logger.info(f"Creating data source '{ds_name}'...")
              config = {"s3": {"bucketName": bucket_name}}
              resp = q.create_data_source(
                  applicationId=app_id,
                  indexId=index_id,
                  displayName=ds_name,
                  configuration=config,
                  roleArn=role_arn
              )
              ds_id = resp['dataSourceId']
              
              def check_ds_status():
                  ds_details = q.get_data_source(applicationId=app_id, indexId=index_id, dataSourceId=ds_id)
                  return ds_details.get('status', 'CREATING'), ds_id

              return wait_for_status(check_ds_status)

          def start_sync(app_id, index_id, ds_id):
              syncs = q.list_data_source_sync_jobs(applicationId=app_id, indexId=index_id, dataSourceId=ds_id)
              # Only start a sync if one has never been run
              if not syncs.get('history'):
                  logger.info(f"Starting initial sync for data source {ds_id}")
                  q.start_data_source_sync_job(applicationId=app_id, indexId=index_id, dataSourceId=ds_id)
              else:
                  logger.info("Sync job history already exists. Skipping initial sync.")

          def ensure_retriever(app_id, index_id, display_name):
              resp = q.list_retrievers(applicationId=app_id)
              for r in resp.get('retrievers', []):
                  if r.get('displayName') == display_name:
                      logger.info(f"Found existing retriever: {r['retrieverId']}")
                      return r['retrieverId']
              
              logger.info("Creating retriever...")
              config = {
                  "nativeIndexConfiguration": {
                      "indexId": index_id
                  }
              }
              resp = q.create_retriever(applicationId=app_id, displayName=display_name, type='NATIVE_INDEX', configuration=config)
              retriever_id = resp['retrieverId']

              def check_retriever_status():
                  retriever_details = q.get_retriever(applicationId=app_id, retrieverId=retriever_id)
                  return retriever_details.get('status', 'CREATING'), retriever_id
              
              return wait_for_status(check_retriever_status, expected_status='ACTIVE')

          def handler(event, context):
              props = event.get('ResourceProperties', {})
              logger.info(f"Received event: {json.dumps(event)}")
              
              if event['RequestType'] == 'Delete':
                  # For safety, do not delete Q resources on stack deletion.
                  send_response(event, context, 'SUCCESS', {})
                  return

              try:
                  account_id = context.invoked_function_arn.split(":")[4]
                  region = context.invoked_function_arn.split(":")[3]
                  
                  app_id = ensure_application(props['ApplicationName'], props['ApplicationIdentityType'])
                  index_id = ensure_index(app_id, props['IndexDisplayName'])
                  
                  bucket_name = props.get('DataSourceBucketName') or f"q-ds-bucket-{account_id}-{region}-{app_id[:8]}"
                  try:
                      s3.head_bucket(Bucket=bucket_name)
                      logger.info(f"Bucket {bucket_name} already exists.")
                  except ClientError:
                      logger.info(f"Creating bucket {bucket_name}")
                      if region != 'us-east-1':
                          s3.create_bucket(Bucket=bucket_name, CreateBucketConfiguration={'LocationConstraint': region})
                      else:
                          s3.create_bucket(Bucket=bucket_name)

                  role_name = f"QDataSourceRole-{app_id[:8]}-{index_id[:8]}"
                  role_arn = ensure_data_source_role(role_name, bucket_name)
                  
                  ds_id = ensure_data_source(app_id, index_id, role_arn, bucket_name, props['DataSourceName'])
                  start_sync(app_id, index_id, ds_id)
                  
                  retriever_id = ensure_retriever(app_id, index_id, "QAppRetriever")
                  
                  data = {
                      'ApplicationId': app_id,
                      'ApplicationArn': f"arn:aws:qbusiness:{region}:{account_id}:application/{app_id}",
                      'IndexId': index_id,
                      'RetrieverId': retriever_id,
                      'DataSourceId': ds_id,
                      'DataSourceBucketName': bucket_name,
                  }
                  send_response(event, context, 'SUCCESS', data)

              except Exception as e:
                  logger.exception("Provisioner failed")
                  send_response(event, context, 'FAILED', reason=str(e))

  QProvisionerCustomResource:
    Type: Custom::QProvisioner
    Properties:
      ServiceToken: !GetAtt QProvisionerFunction.Arn
      ApplicationName: !Ref ApplicationName
      IndexDisplayName: !Ref IndexDisplayName
      DataSourceName: !Ref DataSourceName
      DataSourceBucketName: !Ref DataSourceBucketName
      ApplicationIdentityType: !Ref ApplicationIdentityType

Outputs:
  LambdaFunctionArn:
    Description: ARN of the runtime Lambda function
    Value: !GetAtt AppFunction.Arn
  QApplicationId:
    Description: ApplicationId for the created Amazon Q Business application
    Value: !GetAtt QProvisionerCustomResource.ApplicationId
  QIndexId:
    Description: IndexId for the created Amazon Q Business index
    Value: !GetAtt QProvisionerCustomResource.IndexId
  QRetrieverId:
    Description: RetrieverId for the created Amazon Q Business retriever
    Value: !GetAtt QProvisionerCustomResource.RetrieverId
  QDataSourceId:
    Description: DataSourceId for the created Amazon Q Business data source
    Value: !GetAtt QProvisionerCustomResource.DataSourceId
  QDataSourceBucketName:
    Description: S3 bucket name for the data source
    Value: !GetAtt QProvisionerCustomResource.DataSourceBucketName
Metadata:
  Notes: |
    Before creating the stack, do two things:
    1. Upload your zipped Lambda (containing `main.py` and dependencies) to the
       S3 bucket/key you pass as parameters.
    2. Go to the Amazon Bedrock console in the target region and request access to
       the 'Anthropic Claude 3 Sonnet' model if you haven't already.
